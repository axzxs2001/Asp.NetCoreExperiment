using Azure.Core;
using Microsoft.Extensions.AI;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Connectors.OpenAI;
using ModelContextProtocol.Client;
using ModelContextProtocol.Configuration;
using ModelContextProtocol.Protocol.Transport;
using ModelContextProtocol.Protocol.Types;
using ModelContextProtocol.SemanticKernel.Extensions;
using ModelContextProtocol.Server;
using OpenAI;
using System.Text.Json;
using System.Text.Json.Serialization;

var key = File.ReadAllText("c:/gpt/key.txt");

Console.WriteLine("å›è½¦å¼€å§‹è¿è¡Œï¼š");
Console.ReadLine();
//await MCPClientDemoAsync();
await SKMCPDemoAsync();
Console.ReadLine();

async Task MCPClientDemoAsync()
{ 
    Console.WriteLine("å®¢æˆ·ç«¯è¿æ¥æœåŠ¡ç«¯ä¸­â€¦â€¦");
      
    var serverConfig = new McpServerConfig
    {
        Id = "test",
        Name = "test",
        TransportType = TransportTypes.Sse,
        Location = "http://localhost:3001/sse"
    };
    var opt = new McpClientOptions
    {
        ClientInfo = new()
        {
            Name = "echo-client",
            Version = "1.0.0",
        }
    }; 
    var mcpClient = await McpClientFactory.CreateAsync(serverConfig, opt);

    //Console.WriteLine("å½“å‰å·¥å…·:");
    //var tools = mcpClient.ListToolsAsync();
    //await foreach (var tool in tools)
    //{     
    //    Console.WriteLine($"  {tool.Name}");
    //}
    //Console.WriteLine();

    IList<AIFunction> functions = await mcpClient.GetAIFunctionsAsync();
    IChatClient chatClient = new OpenAIClient(key).AsChatClient("gpt-4o-mini")
    .AsBuilder().UseFunctionInvocation().Build();
    var response = chatClient.GetStreamingResponseAsync(
     "è°ƒç”¨ echo tool å‚æ•°ç”¨ 'Hello Gui SuWei!'ï¼Œç„¶åæŠŠresponseè¿”å›",
     new()
     {
         Tools = [.. functions],
     });
    await foreach (var item in response)
    {
        Console.Write(item.Text);
    }
}

async Task SKMCPDemoAsync()
{
    var builder = Kernel.CreateBuilder();
    builder.Services.AddLogging(c => c.AddDebug().SetMinimumLevel(LogLevel.Trace));

    builder.Services.AddOpenAIChatCompletion(
        serviceId: "openai",
        modelId: "gpt-4o-mini",
        apiKey: key);

    var kernel = builder.Build();
    //var transportOptions = new Dictionary<string, string>
    //{
    //    ["command"] = "npx",
    //    ["arguments"] = "-y --verbose @modelcontextprotocol/server-everything"
    //};
    //// ğŸ’¡ Add this line to enable MCP functions from a Stdio server named "Everything"
    //await kernel.Plugins.AddMcpFunctionsFromStdioServerAsync("Everything", transportOptions);
    try
    {
        await kernel.Plugins.AddMcpFunctionsFromSseServerAsync("echo", "http://localhost:3001/sse");
    }
    catch
    {

    }

    var executionSettings = new OpenAIPromptExecutionSettings
    {
        Temperature = 0,
        FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
    };

    var prompt = "è°ƒç”¨ echo tool å‚æ•°ç”¨ 'Hello Gui SuWei!'ï¼Œç„¶åæŠŠresponseè¿”å›";
    var result = await kernel.InvokePromptAsync(prompt, new(executionSettings)).ConfigureAwait(false);
    Console.WriteLine($"\n\n{prompt}\n{result}");
}